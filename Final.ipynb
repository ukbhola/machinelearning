{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TALENT ANALYTICS\n",
    "\n",
    "## Dataset : [Predicting Salary and Insights]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "import xlsxwriter\n",
    "from xlsxwriter.utility import xl_rowcol_to_cell\n",
    "\n",
    "# convert T/F to 1/0\n",
    "def convertTF(df,featureList):\n",
    "    d = {True:1, False:0}\n",
    "    for feature in featureList:\n",
    "        df[feature] = df[feature].apply(lambda x: d[x])\n",
    "    return df\n",
    "\n",
    "def yearReturn(x):\n",
    "    return x.year\n",
    "\n",
    "def pos(x):\n",
    "    if x > 0: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def neg(x):\n",
    "    if x < 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def val(x):\n",
    "    if x > 0.44:\n",
    "        return 3\n",
    "    elif x < -0.44:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def conv_english(x) :\n",
    "    if x >= 520:\n",
    "        return 3\n",
    "    elif x < 420:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def conv_logical(x) :\n",
    "    if x >= 600:\n",
    "        return 3\n",
    "    elif x < 450:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def conv_quant(x) :\n",
    "    if x >= 600:\n",
    "        return 3\n",
    "    elif x < 500:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def conv_prog(x) :\n",
    "    if x >= 600:\n",
    "        return 3\n",
    "    elif x < 500:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def gpaCal(x):\n",
    "    if x <= 10:\n",
    "        return x*10\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def isNationalBoard(row):\n",
    "    if (row['isCbse'] or row['isISC'] or row['isICSE']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prepare(ds):\n",
    "    ## extracting designation features from designation string\n",
    "    ds['isSenior'] = ds.Designation.str.contains('senior')\n",
    "    ds['isSoftware'] = ds.Designation.str.contains('software')\n",
    "    ds['isManager'] = ds.Designation.str.contains('manager')\n",
    "    ds['isEngineer'] = ds.Designation.str.contains('engineer')\n",
    "    ds['isDeveloper'] = ds.Designation.str.contains('developer')\n",
    "    \n",
    "    ## extracting degree features into boolean vectors\n",
    "    ds['isBtech'] = ds.Degree.str.contains('B.Tech/B.E.')\n",
    "    ds['isMCA'] = ds.Degree.str.contains('MCA')\n",
    "    ds['isMtech'] = ds.Degree.str.contains('M.Tech./M.E.')\n",
    "    \n",
    "    ## extract the board information\n",
    "    ds['isCbse'] = ds['12board'].str.contains('cbse')\n",
    "    ds['isStateBoard'] = ds['12board'].str.contains('state board')\n",
    "    ds['isISC'] = ds['12board'].str.contains('isc')\n",
    "    ds['isICSE'] = ds['12board'].str.contains('icse')\n",
    "    ds['isCbse'].fillna(value = False, inplace = True)\n",
    "    ds['isStateBoard'].fillna(value = False, inplace = True)\n",
    "    ds['isISC'].fillna(value = False, inplace = True)\n",
    "    ds['isICSE'].fillna(value = False, inplace = True)\n",
    "    ds['isNationalBoard'] = 0\n",
    "    ds['isNationalBoard'] = ds.apply(lambda x : isNationalBoard(x), axis=1)\n",
    "    \n",
    "    \n",
    "    ## extract the specialization information\n",
    "    ds['isCSE'] = ds.Specialization.str.contains('computer engineering')\n",
    "    ds['isECE'] = ds.Specialization.str.contains('electronics and communication engineering')\n",
    "    ds['isIT'] = ds.Specialization.str.contains('information technology')\n",
    "    ds['isMech'] = ds.Specialization.str.contains('mechanical engineering')\n",
    "    ds['isICE'] = ds.Specialization.str.contains('instrumentation and control engineering')\n",
    "    ds['isEE'] = ds.Specialization.str.contains('electrical engineering')\n",
    "    \n",
    "    ds = convertTF(ds, ['isCbse', 'isStateBoard', 'isISC', 'isICSE', 'isBtech', 'isMCA', 'isMtech', 'isSenior', 'isSoftware', 'isManager', 'isEngineer', 'isDeveloper','isCSE', 'isECE', 'isIT', 'isMech', 'isICE', 'isEE'])\n",
    "    \n",
    "    ## Cleaning the data\n",
    "\n",
    "    #train.ComputerProgramming.replace(-1,None, inplace=True)\n",
    "    m = ds.ComputerProgramming.mean(skipna=True)\n",
    "    ds.ComputerProgramming.fillna(m, inplace=True)\n",
    "\n",
    "    #train.Domain.replace(-1, None, inplace=True)\n",
    "    n = ds.Domain.mean(skipna=True)\n",
    "    ds.Domain.fillna(n, inplace=True)\n",
    "\n",
    "    ds.GraduationYear.replace(0,None,inplace=True)\n",
    "    m = ds.GraduationYear.mean(skipna=True)\n",
    "    ds.GraduationYear.fillna(m, inplace=True)\n",
    "    \n",
    "    # Mining different features\n",
    "\n",
    "    #MaxDomain : max of the domains in one column\n",
    "    ds['maxDomain'] = ds[['ComputerProgramming','ComputerScience','ElectronicsAndSemicon','MechanicalEngg','ElectricalEngg','TelecomEngg','CivilEngg']].max(axis=1)\n",
    "\n",
    "    # diffGrad : difference between Graduation Year & 12th graduation, to see whether drop in college affect scores\n",
    "    ds['diffGrad'] = ds.GraduationYear - ds['12graduation']\n",
    "\n",
    "    # diffGradDOB : difference between Graduation Year and DOB\n",
    "\n",
    "    ds['DOBY'] = ds.DOB.apply(yearReturn)\n",
    "    ds['diffGradDOB'] = ds.GraduationYear - ds.DOBY\n",
    "    \n",
    "    # Big Five scores\n",
    "    ds['bigfive'] = 0\n",
    "    ds.bigfive += ds.agreeableness.apply(lambda x : val(x))\n",
    "    ds.bigfive += ds.conscientiousness.apply(lambda x : val(x))\n",
    "    ds.bigfive += ds.nueroticism.apply(lambda x : val(x))\n",
    "    ds.bigfive += ds.extraversion.apply(lambda x : val(x))\n",
    "    ds.bigfive += ds.openess_to_experience.apply(lambda x : val(x))\n",
    "    \n",
    "    # Translate English / Logical / Quants scores\n",
    "    ds['scores'] = 0\n",
    "    ds['scores'] += ds.English.apply(lambda x : conv_english(x))\n",
    "    ds['scores'] += ds.Logical.apply(lambda x : conv_logical(x))\n",
    "    ds['scores'] += ds.Quant.apply(lambda x : conv_quant(x))\n",
    "    ds['scores'] += ds.ComputerProgramming.apply(lambda x : conv_prog(x))\n",
    "    \n",
    "    # Fix GPA to 100 scale\n",
    "    ds['mcolgGPA'] = ds.collegeGPA.apply(lambda x: gpaCal(x))\n",
    "    \n",
    "    #Feature columns to take\n",
    "    feature_cols = ['10percentage','12percentage', 'mcolgGPA', 'CollegeTier','CollegeCityTier', 'GraduationYear','scores','Domain','maxDomain','bigfive','diffGradDOB','isCSE','isIT','isECE','isMech','isICE','isEE']\n",
    "    \n",
    "    #X & Y vals\n",
    "    X = ds[feature_cols]\n",
    "    y = ds.Salary\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def display_metrics(y_test, y_pred):\n",
    "    print \"MAE : %f\" % metrics.mean_absolute_error(y_test, y_pred)\n",
    "    print \"MSE : %f\" % metrics.mean_squared_error(y_test, y_pred)\n",
    "    print \"RMSE : %f\" % np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    print \"\\n\"\n",
    "\n",
    "def model_train(model,X,y):\n",
    "    # split test, train\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 1)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    display_metrics(y_test, y_pred)\n",
    "    \n",
    "def training(X,y):\n",
    "    \n",
    "    #SVM Regression\n",
    "    svm_clf = svm.SVR()\n",
    "    print \"SVM Regression\"\n",
    "    model_train(svm_clf, X, y)\n",
    "    \n",
    "    #Random Forests\n",
    "    rand_clf = RandomForestRegressor(n_estimators = 1500,max_features='sqrt')\n",
    "    print \"Random Forests\"\n",
    "    model_train(rand_clf, X, y)\n",
    "    \n",
    "    #Linear SVM Regression\n",
    "    linear_svm_clf = svm.LinearSVR()\n",
    "    print \"Linear SVM Regression\"\n",
    "    model_train(linear_svm_clf, X, y)\n",
    "    \n",
    "    #Lasso Regression\n",
    "    lasso_clf = linear_model.Lasso(alpha=0.01, selection=\"random\", random_state=1)\n",
    "    print \"Lasso Regression\"\n",
    "    model_train(lasso_clf, X, y)\n",
    "    \n",
    "    #Linear Regression\n",
    "    linear_clf = LinearRegression()\n",
    "    print \"Linear Regression\"\n",
    "    model_train(linear_clf, X, y)\n",
    "    \n",
    "    #Logistic Regression\n",
    "    logistic_clf = linear_model.LogisticRegression()\n",
    "    print \"Logistic Regression\"\n",
    "    model_train(logistic_clf, X, y)\n",
    "    \n",
    "    return svm_clf, rand_clf, linear_svm_clf, lasso_clf, linear_clf\n",
    "\n",
    "\n",
    "def testing(X, model, ds, file_name):\n",
    "    #run model on testing & save submission\n",
    "    y_pred = model.predict(X)\n",
    "    submission = pd.DataFrame(columns=['ID','Salary'])\n",
    "    submission.ID = ds.ID\n",
    "    submission.Salary = y_pred\n",
    "    writer_orig = pd.ExcelWriter(file_name, engine='xlsxwriter')\n",
    "    submission.to_excel(writer_orig, index=False, sheet_name='report')\n",
    "    writer_orig.save()    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train  = pd.read_excel('train.xlsx', na_values=-1)\n",
    "print(train.shape)\n",
    "\n",
    "X, y = prepare(train)\n",
    "svm_clf, rand_clf, linear_svm_clf, lasso_clf, linear_clf = training(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the least RMSE was reported by **Lasso Regression**. We perform the final prediction on the test set using it : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test  = pd.read_excel('test.xlsx', na_values=-1)\n",
    "print(test.shape)\n",
    "\n",
    "X, y = prepare(test)\n",
    "testing(X, lasso_clf, test, 'submission.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "m1 = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "m2 = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "m3 = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "m4 = MinMaxScaler(feature_range=(0.0, 1.0))\n",
    "X_train_minmax = m1.fit_transform(X_train)\n",
    "y_train_minmax = m2.fit_transform(y_train.reshape(-1,1))\n",
    "X_test_minmax = m3.fit_transform(X_test)\n",
    "y_test_minmax = m4.fit_transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sknn import mlp\n",
    "from sknn.mlp import Layer\n",
    "\n",
    "clf = mlp.Regressor(layers=[\n",
    "        Layer(\"Rectifier\", units=2000),\n",
    "        Layer(\"Linear\")],\n",
    "    learning_rate=0.00002,\n",
    "    n_iter=1000)\n",
    "\n",
    "clf.fit(X_train_minmax, y_train_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pr = clf.predict(X_test_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_p1 = m4.inverse_transform(y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display_metrics(y_test,y_p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#cols = ['openess_to_experience', 'conscientiousness', 'agreeableness', 'extraversion', 'nueroticism']\n",
    "#cols = ['maxDomain','Quant','Logical','English']\n",
    "#cols = ['scores', 'CollegeCityTier', 'isNationalBoard']\n",
    "cols = ['10percentage','12percentage', 'mcolgGPA', 'CollegeTier','CollegeCityTier', 'GraduationYear','scores','Domain','maxDomain','bigfive','diffGradDOB','isCSE','isIT','isECE','isMech','isICE','isEE']\n",
    "\n",
    "sns.pairplot(train, x_vars = cols[:4], y_vars = 'Salary', size = 7, aspect = 0.7)\n",
    "sns.pairplot(train, x_vars = cols[4:8], y_vars = 'Salary', size = 7, aspect = 0.7)\n",
    "sns.pairplot(train, x_vars = cols[8:12], y_vars = 'Salary', size = 7, aspect = 0.7)\n",
    "sns.pairplot(train, x_vars = cols[12:], y_vars = 'Salary', size = 7, aspect = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Histogram of Salary\n",
    "sns.set_context(\"poster\")\n",
    "sns.distplot(train.Salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train  = pd.read_excel('train.xlsx', na_values=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.JobCity = train.JobCity.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.JobCity = train.JobCity.str.rstrip()\n",
    "train.JobCity = train.JobCity.str.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# City cleaning process\n",
    "train.JobCity = train.JobCity.str.replace('banglore','bangalore')\n",
    "train.JobCity = train.JobCity.str.replace('delhi','new delhi')\n",
    "train.JobCity = train.JobCity.str.replace('new dehli','new delhi')\n",
    "train.JobCity = train.JobCity.str.replace('new delhi/ncr','new delhi')\n",
    "train.JobCity = train.JobCity.str.replace('ncr','new delhi')\n",
    "train.JobCity = train.JobCity.str.replace('navi mumbai','mumbai')\n",
    "train.JobCity = train.JobCity.str.replace('mumbai , hyderabad','mumbai')\n",
    "train.JobCity = train.JobCity.str.replace('new new delhi','new delhi')\n",
    "train.JobCity = train.JobCity.str.replace('asifabadbangalore','bangalore')\n",
    "train.JobCity = train.JobCity.str.replace('bengaluru','bangalore')\n",
    "train.JobCity = train.JobCity.str.replace('greater noida','noida')\n",
    "train.JobCity = train.JobCity.str.replace('nouda','noida')\n",
    "train.JobCity = train.JobCity.str.replace('banagalore','bangalore')\n",
    "train.JobCity = train.JobCity.str.replace('banaglore','bangalore')\n",
    "train.JobCity = train.JobCity.str.replace('a-64,sec-64,noida','noida')\n",
    "train.JobCity = train.JobCity.str.replace('technopark, trivandrum','trivandrum')\n",
    "train.JobCity = train.JobCity.str.replace('vizag','visakhapatnam')\n",
    "train.JobCity = train.JobCity.str.replace('vsakhapttnam','visakhapatnam')\n",
    "train.JobCity = train.JobCity.str.replace('thiruvananthapuram','trivandrum')\n",
    "train.JobCity = train.JobCity.str.replace('ambala city','ambala')\n",
    "train.JobCity = train.JobCity.str.replace('kudankulam ,tarapur','kundankulam')\n",
    "train.JobCity = train.JobCity.str.replace('gaziabaad','ghaziabad')\n",
    "train.JobCity = train.JobCity.str.replace('gajiabaad','ghaziabad')\n",
    "train.JobCity = train.JobCity.str.replace('bhubaneswar','bhubaneshwar')\n",
    "train.JobCity = train.JobCity.str.replace('bhubneshwar','bhubaneshwar')\n",
    "train.JobCity = train.JobCity.str.replace('guragaon','gurgaon')\n",
    "train.JobCity = train.JobCity.str.replace('gurgoan','gurgaon')\n",
    "train.JobCity = train.JobCity.str.replace('kolkata`','kolkata')\n",
    "train.JobCity = train.JobCity.str.replace('sonepat','sonipat')\n",
    "train.JobCity = train.JobCity.str.replace('baroda','vadodara')\n",
    "train.JobCity = train.JobCity.str.replace('hderabad','hyderabad')\n",
    "train.JobCity = train.JobCity.str.replace('pondi','pondy')\n",
    "train.JobCity = train.JobCity.str.replace('punchkula','panchkula')\n",
    "train.JobCity = train.JobCity.str.replace('muzzafarpur','muzaffarpur')\n",
    "train.JobCity = train.JobCity.str.replace('kochi/cochin, chennai and coimbatore','kochi/cochin')\n",
    "train.JobCity = train.JobCity.str.replace('nasikcity','nashik')\n",
    "train.JobCity = train.JobCity.str.replace('sahibabad','shahibabad')\n",
    "train.JobCity = train.JobCity.str.replace('punr','pune')\n",
    "train.JobCity = train.JobCity.str.replace('tirupati','tirupathi')\n",
    "train.JobCity = train.JobCity.str.replace('sadulpur,rajgarh,distt-churu,rajasthan','sadulpur')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Google API's to get lattitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import simplejson\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "googleGeocodeUrl = 'http://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "def get_coordinates(query, from_sensor=False):\n",
    "    latitude, longitude = None, None\n",
    "    if isinstance(query, basestring):\n",
    "        query = query.encode('utf-8')\n",
    "        params = {\n",
    "            'address': query,\n",
    "            'sensor': \"true\" if from_sensor else \"false\"\n",
    "        }\n",
    "        url = googleGeocodeUrl + urllib.urlencode(params)\n",
    "        json_response = urllib.urlopen(url)\n",
    "        response = simplejson.loads(json_response.read())\n",
    "        if response['results']:\n",
    "            location = response['results'][0]['geometry']['location']\n",
    "            latitude, longitude = round(location['lat'],3), round(location['lng'],3)\n",
    "            print query, latitude, longitude\n",
    "        else:\n",
    "            print query, \"<no results>\"\n",
    "    time.sleep(1)\n",
    "    clear_output()\n",
    "    return [latitude, longitude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get all city coordinates and store them in a new column\n",
    "viz['JobCityCoords'] = 0\n",
    "\n",
    "viz.JobCityCoords = viz.JobCity.apply(lambda x : get_coordinates(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz['city_lat'] = viz.JobCityCoords.apply(lambda x : x[0])\n",
    "viz['city_lon'] = viz.JobCityCoords.apply(lambda x : x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer_orig = pd.ExcelWriter('vizualization_data.xlsx', engine='xlsxwriter')\n",
    "viz.to_excel(writer_orig, index=False, sheet_name='viz')\n",
    "writer_orig.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Clubbing of Designations into similar ones\n",
    "train.Designation = train.Designation.str.replace(\"software test engineer\",\"STE\")\n",
    "train.Designation = train.Designation.str.replace(\"test engineer\",\"STE\")\n",
    "train.Designation = train.Designation.str.replace(\"STE\",\"software test engineer\")\n",
    "train.Designation = train.Designation.str.replace(\"system engineer\",\"systems engineer\")\n",
    "train.Designation = train.Designation.str.replace(\"associate software engineer\",\"software engineer\")\n",
    "train.Designation = train.Designation.str.replace(\"software developer\",\"software engineer\")\n",
    "train.Designation = train.Designation.str.replace(\"java software engineer\",\"java developer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vc = train.Designation.value_counts()\n",
    "print vc[vc > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vd = vc[vc > 20].reset_index()\n",
    "labels = vd['index']\n",
    "explode = np.zeros(vd.shape[0])\n",
    "explode[0] = 0.1\n",
    "# print explode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "plt.pie(vd['Designation'], labels=labels, explode = explode,\n",
    "        autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "\n",
    "# Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "plt.axis('equal')\n",
    "# plt.legend(patches, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grp = train.groupby('Designation')['ComputerProgramming'].agg({'mean' : np.mean, 'std' : np.std,'count' : lambda ts: (ts > 0).sum()})\n",
    "quants = grp[grp['count'] > 30].sort_values(by='count',ascending=False)['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### College Tier and College City Tier Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gr = train.groupby('CollegeTier')['Salary'].agg({'mean' : np.mean, 'std' : np.std})\n",
    "#gr.reset_index(inplace=True)\n",
    "gd = train.groupby('CollegeCityTier')['Salary'].agg({'mean' : np.mean, 'std' : np.std})\n",
    "gd.reset_index(inplace=True)\n",
    "sns.set_style(\"white\")\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)\n",
    "side_plot = sns.barplot(x=\"CollegeTier\",y=\"mean\",data=gr, ax=ax1)\n",
    "bottom_plot = sns.barplot(x=\"CollegeCityTier\", y=\"mean\", data=gd,ax=ax2)\n",
    "#topbar = plt.Rectangle((0,0),1,1,fc=\"red\", edgecolor = 'none')\n",
    "#bottombar = plt.Rectangle((0,0),1,1,fc='#0000A3',  edgecolor = 'none')\n",
    "#l = plt.legend([bottombar, topbar], ['Bottom Bar', 'Top Bar'], loc=1, ncol = 2, prop={'size':16})\n",
    "#l.draw_frame(False)\n",
    "\n",
    "#Optional code - Make plot look nicer\n",
    "sns.despine(left=True)\n",
    "side_plot.set_ylabel(\"Mean Salary\")\n",
    "bottom_plot.set_ylabel(\"\")\n",
    "bottom_plot.set_xlabel(\"College City Tier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specializations Distributions\n",
    "\n",
    "Clubbing few similar specializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.Specialization = train.Specialization.str.replace('computer application','C.S.E')\n",
    "train.Specialization = train.Specialization.str.replace('computer engineering','C.S.E')\n",
    "train.Specialization = train.Specialization.str.replace('C.S.E','computer science & engineering')\n",
    "train.Specialization = train.Specialization.str.replace('electronics & instrumentation eng','electronics and instrumentation engineering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ge = train.groupby('Specialization')['Salary'].agg({'mean' : np.mean, 'std' : np.std, 'count' : lambda ts: (ts > 0).sum(), 'max' : np.max})\n",
    "ge.reset_index(inplace=True)\n",
    "fd = ge.sort_values(by='max',ascending=False)[0:10]\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd.Specialization = fd.Specialization.str.replace(\"computer science & engineering\",\"CSE\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"electronics and communication engineering\",\"ECE\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"electronics and electrical engineering\",\"EEE\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"electronics & instrumentation eng\",\"EIE\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"information technology\",\"IT\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"electrical engineering\",\"EE\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"mechanical engineering\",\"ME\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"instrumentation and control engineering\",\"ICE\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"applied electronics and instrumentation\",\"AEI\")\n",
    "fd.Specialization = fd.Specialization.str.replace(\"civil engineering\",\"CE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd.Specialization = fd.Specialization.str.replace(\"electronics and instrumentation engineering\",\"EIE\")\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op = sns.barplot(x=\"Specialization\", y=\"max\", data=fd)\n",
    "sns.set_context(\"poster\")\n",
    "sns.despine(left=True)\n",
    "op.set_ylabel(\"Max Salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = pd.DataFrame()\n",
    "df['ComputerProgramming'] = quants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Designation\", y=\"Quant\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer_orig = pd.ExcelWriter('exploration.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer_orig, index=False, sheet_name='report')\n",
    "writer_orig.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores By Designation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "n_groups = 10\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(15,10)\n",
    "ax.set(ylim=[450, 600])\n",
    "index = np.arange(0, n_groups * 2, 2)\n",
    "print index\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "means_men = (20, 35, 30, 35, 27)\n",
    "means_women = (25, 32, 34, 20, 25)\n",
    "\n",
    "rects1 = plt.bar(index, df.Quant[0:10], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 error_kw=error_config,\n",
    "                 label='Quant')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, df.English[0:10], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 error_kw=error_config,\n",
    "                 label='English')\n",
    "\n",
    "rects3 = plt.bar(index + bar_width * 2, df.Logical[0:10], bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='g',\n",
    "                 error_kw=error_config,\n",
    "                 label='Logical')\n",
    "\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by Designation')\n",
    "plt.xticks(index + bar_width, df.Designation[0:10], rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz  = pd.read_excel('vizualization_data.xlsx', na_values=-1)\n",
    "viz_new = viz[viz['count'] > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# import folium\n",
    "\n",
    "lat = 23.051013\n",
    "lon = 78.242494\n",
    "\n",
    "map_osm = folium.Map(location=[lat, lon],tiles='Stamen Toner', zoom_start=5)\n",
    "fill_color_g = '#FF1A1A'\n",
    "fill_color_border_g = '#FF2F1A'\n",
    "fill_color_a = '#ff751a'\n",
    "fill_color_border_a = '#e65b00'\n",
    "fill_color_l = '#FFB91A'\n",
    "fill_color_border_l = '#FF991A'\n",
    "\n",
    "field = 'quant'\n",
    "for name, row in viz_new.iterrows():\n",
    "    fill_color = ''\n",
    "    line_color = ''\n",
    "    if int(row[field]) > 520:\n",
    "        fill_color = fill_color_g\n",
    "        line_color = fill_color_border_g\n",
    "    elif int(row[field]) > 500:\n",
    "        fill_color = fill_color_a\n",
    "        line_color = fill_color_border_a\n",
    "    else :\n",
    "        fill_color = fill_color_l\n",
    "        line_color = fill_color_border_l\n",
    "    map_osm.circle_marker(location=[row[\"city_lat\"], row[\"city_lon\"]],radius=(int(row[field]) - 450) * 1000, popup=row[\"JobCity\"], fill_color=fill_color, line_color=line_color)\n",
    "    #map_osm.simple_marker([row[\"city_lat\"], row[\"city_lon\"]], popup=row[\"JobCity\"])\n",
    "    map_osm.polygon_marker(location=[row[\"city_lat\"], row[\"city_lon\"]],\n",
    "                     fill_color=fill_color, num_sides=3, radius=(int(row[field]) - 450) * 0.2)\n",
    "map_osm.create_map(path='test.html')\n",
    "map_osm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
